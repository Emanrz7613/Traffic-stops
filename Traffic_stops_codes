import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import data_table
from google.colab import drive

#mount google drive to read data
dataFile = 'Officer_Traffic_Stops.csv'


drive.mount('/content/drive')
path = '/content/drive/MyDrive/DSBA6156_project/'+ dataFile
traffic_stops_df = pd.read_csv(path,sep=",",encoding='ISO-8859-1')
drive.flush_and_unmount()



traffic_stops_df.head()

# Display basic information about the dataset
print(traffic_stops_df.info())

# Convert 'Month_of_Stop' to datetime object
traffic_stops_df['Month_of_Stop'] = pd.to_datetime(traffic_stops_df['Month_of_Stop'], format='%Y/%m')

# Convert 'Was_a_Search_Conducted' to boolean
traffic_stops_df['Was_a_Search_Conducted'] = traffic_stops_df['Was_a_Search_Conducted'].apply(lambda x: True if x == 'YES' else False)

# Display class counts for categorical variables
categorical_cols = ['Reason_for_Stop', 'Officer_Race', 'Officer_Gender', 'Driver_Race', 'Driver_Ethnicity', 'Driver_Gender', 'Result_of_Stop', 'CMPD_Division']

for col in categorical_cols:
    print(f"\nClass Counts for {col}:")
    print(traffic_stops_df[col].value_counts())

# 1. Handling Missing Data
# Check for missing values
missing_values = traffic_stops_df.isna().sum()
print("\nMissing Values in Each Column:\n", missing_values)

# Fill missing categorical columns with 'Unknown'
traffic_stops_df[categorical_cols] = traffic_stops_df[categorical_cols].fillna('Unknown')

# Fill missing numerical columns with median
numerical_cols = ['Officer_Years_of_Service', 'Driver_Age']
for col in numerical_cols:
    traffic_stops_df[col].fillna(traffic_stops_df[col].median(), inplace=True)

# 2. Exploratory Data Analysis (EDA)
# Plot distribution of traffic stops by Driver Race
plt.figure(figsize=(10, 6))
sns.countplot(data=traffic_stops_df, x='Driver_Race', order=traffic_stops_df['Driver_Race'].value_counts().index)
plt.title('Distribution of Traffic Stops by Driver Race')
plt.xlabel('Driver Race')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

# Plot distribution of traffic stops by Reason for Stop
plt.figure(figsize=(12, 6))
sns.countplot(data=traffic_stops_df, x='Reason_for_Stop', order=traffic_stops_df['Reason_for_Stop'].value_counts().index)
plt.title('Distribution of Traffic Stops by Reason for Stop')
plt.xlabel('Reason for Stop')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

# # Plot class balance for the target variable
# plt.figure(figsize=(8, 5))
# sns.countplot(x=y, palette='viridis')
# plt.title('Class Balance for Target Variable')
# plt.xlabel('Was a Search Conducted (0 = No, 1 = Yes)')
# plt.ylabel('Count')
# plt.show()

# 3. Classification Model Preparation
from sklearn.model_selection import train_test_split, GridSearchCV, ParameterGrid
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, RocCurveDisplay
from imblearn.over_sampling import SMOTE
from xgboost import XGBClassifier

# Encode categorical features
encoder = LabelEncoder()
categorical_features = ['Reason_for_Stop', 'Officer_Race', 'Officer_Gender', 'Driver_Race', 'Driver_Ethnicity', 'Driver_Gender', 'CMPD_Division']
for feature in categorical_features:
    traffic_stops_df[feature] = encoder.fit_transform(traffic_stops_df[feature])

# Prepare features and target for classification
X = traffic_stops_df[['Reason_for_Stop', 'Officer_Race', 'Officer_Gender', 'Officer_Years_of_Service',
                      'Driver_Race', 'Driver_Ethnicity', 'Driver_Gender', 'Driver_Age', 'CMPD_Division']]
y = traffic_stops_df['Was_a_Search_Conducted'].astype(int)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train a Random Forest Classifier
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier.fit(X_train, y_train)

# Make predictions
y_pred = rf_classifier.predict(X_test)

# Classification report
print("\nClassification Report:\n")
print(classification_report(y_test, y_pred))

# Feature Importance
feature_importances = rf_classifier.feature_importances_
features = X.columns
importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})
importance_df = importance_df.sort_values(by='Importance', ascending=False)
print("\nFeature Importances:\n")
print(importance_df)

plt.figure(figsize=(10, 6))
plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')
plt.xlabel('Importance')
plt.title('Feature Importances')
plt.gca().invert_yaxis()
plt.show()

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# AUC Score and ROC Curve
y_prob = rf_classifier.predict_proba(X_test)[:, 1]
auc_score = roc_auc_score(y_test, y_prob)
print(f"\nAUC Score: {auc_score:.2f}")

RocCurveDisplay.from_estimator(rf_classifier, X_test, y_test)
plt.title('ROC Curve')
plt.show()

# Use SMOTE to oversample and balance the training set
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)

# Plot class balance after oversampling
plt.figure(figsize=(8, 5))
sns.countplot(x=y_train_balanced, palette='viridis')
plt.title('Class Balance After SMOTE Oversampling')
plt.xlabel('Was a Search Conducted (0 = No, 1 = Yes)')
plt.ylabel('Count')
plt.show()

# Perform GridSearchCV to find the best hyperparameters for XGBoost
param_grid = {
    'n_estimators': [50, 100, 150],
    'max_depth': [3, 6, 10],
    'learning_rate': [0.01, 0.1, 0.2],
    'subsample': [0.6, 0.8, 1.0]
}
grid_search = GridSearchCV(XGBClassifier(tree_method='gpu_hist', use_label_encoder=False, eval_metric='auc', random_state=42), param_grid, cv=3, scoring='f1', n_jobs=-1)
grid_search.fit(X_train_balanced, y_train_balanced)

# Train the best XGBoost Classifier
best_xgb_classifier = grid_search.best_estimator_
print("\nBest Parameters from GridSearchCV:\n", grid_search.best_params_)

# Make predictions
y_pred = best_xgb_classifier.predict(X_test)

# Classification report
print("\nClassification Report:\n")
print(classification_report(y_test, y_pred))

# Feature Importance
feature_importances = best_xgb_classifier.feature_importances_
features = X.columns
importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})
importance_df = importance_df.sort_values(by='Importance', ascending=False)
print("\nFeature Importances:\n")
print(importance_df)

plt.figure(figsize=(10, 6))
plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')
plt.xlabel('Importance')
plt.title('Feature Importances')
plt.gca().invert_yaxis()
plt.show()

# AUC Score and ROC Curve
y_prob = best_xgb_classifier.predict_proba(X_test)[:, 1]
auc_score = roc_auc_score(y_test, y_prob)
print(f"\nAUC Score: {auc_score:.2f}")

RocCurveDisplay.from_estimator(best_xgb_classifier, X_test, y_test)
plt.title('ROC Curve')
plt.show()
